---
title: "p8105_hw3_lk2761"
author: "Lorraine Kwok"
date: "October 8, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
	fig.width = 7, 
  fig.height = 6,
  out.width = "90%")

library(tidyverse)
```

## Problem 1 

We are using Instacart data. 

```{r load in Instacart dataset}
library(p8105.datasets) 
data("instacart")
```

```{r count number of aisles}
# This code produces a new dataframe that shows the number of distinct aisles and the number of items ordered from each. 

num_aisles_df = 
  instacart %>%
  count(aisle) %>%
  rename(.data = ., num_items_ordered = n) %>%
  arrange(desc(num_items_ordered)) 
```

```{r}
num_aisles_df %>%
  filter(.data = ., num_items_ordered > 10000) %>%
  ggplot() + 
  geom_col(aes(x = aisle, y = num_items_ordered)) +
theme_minimal() +
  theme(axis.title = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Number of items ordered per aisle", 
       x = "Name of aisle",
       y = "Number of items ordered") 
```

```{r create table for most popular items in three specific aisles}
# Create a table that shows the three most popular items in each of the aisles: baking ingredients, dog food care and packaged vegetables fruits.

num_pop_items_df =
  instacart %>%
  group_by(aisle) %>%
  select(.data = ., aisle, product_name) %>%
  filter(.data = ., aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  count(product_name) %>%
  rename(.data = ., num_products = n) %>%
  arrange(desc(num_products)) %>%
  top_n(3) %>%
  pivot_wider(
    names_from = "aisle",
    values_from = "num_products"
  ) 

knitr::kable(num_pop_items_df)
```

```{r}
mean_hr_day_df = 
  instacart %>%
  select(.data = ., product_name, order_dow, order_hour_of_day) %>%
  mutate(.data = ., 
         order_dow = recode(order_dow, 
                            `0` = "Sunday",
                            `1` = "Monday",
                            `2` = "Tuesday", 
                            `3` = "Wednesday",
                            `4` = "Thursday", 
                            `5` = "Friday", 
                            `6` = "Saturday")) %>%
  filter(.data = ., product_name == "Pink Lady Apple" | product_name == "Coffee Ice Cream") %>%
  arrange(product_name, order_dow) %>%
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hr_day = round(mean(order_hour_of_day), 2)
  ) %>%
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hr_day"
  ) %>%
  select(.data = ., Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)

knitr::kable(mean_hr_day_df)
```

## Problem 2

This problem uses the BRFSS dataset. 

```{r load in BRFSS dataset}
library(p8105.datasets)
data("brfss_smart2010")

# Clean the data
brfss_smart2010_tidy =
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(.data = ., 
         topic == "Overall Health",
         response == "Excellent" | response == "Fair" | response == "Good" | response == "Poor" | response == "Very good") %>% 
  mutate(.data = ., 
         state_name = state.name[match(locationabbr, state.abb)],
         response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
  rename(.data = ., state_abbr = locationabbr, state_county = locationdesc) %>%
  filter(.data = ., topic == "Overall Health") %>%
  select(.data = ., year, state_abbr, state_name, state_county, topic, response, data_value)
```

```{r create dataframe for states in 2002 and 2010}
num_states_2002 = 
  brfss_smart2010_tidy %>%
  janitor::clean_names() %>%
  mutate(.data = . ,) %>%
  filter(.data = ., year == "2002") %>%
  count(state_name) %>%
  rename(.data = ., num_locations = n) %>%
  filter(.data = ., num_locations >= 7) 

num_states_2002

num_states_2010 = 
  brfss_smart2010_tidy %>%
  janitor::clean_names() %>%
  filter(.data = ., year == "2010") %>%
  count(state_name) %>%
  rename(.data = ., num_locations = n) %>%
  filter(.data = ., num_locations >= 7) 

num_states_2010
```

In 2002, the following states `r pull(num_states_2002, state_name)` were observed in 7 or more locations. In 2010, the following states `r pull(num_states_2010, state_name)` were observed in 7 or more locations.

```{r create new dataset with only excellent responses for Overall Health}

excellent_df = 
  brfss_smart2010_tidy %>%
  janitor::clean_names() %>%
  filter(.data = ., response == "Excellent") %>%
  group_by(state_abbr) %>%
  mutate(.data = . ,
         avg_data_value = mean(data_value, na.rm = TRUE)) %>%
  select(.data = . , year, state_name, avg_data_value)

# This code creates a "spaghetti" plot showing the average data values across years for each state. 

ggplot(excellent_df, aes(group = state_name, x = year, y = avg_data_value, color = state_name)) + 
  geom_line()
```

```{r}
# This code creates a new dataset that consists of NY state data values and responses to the "Overall Health" topic for 2006 and 2010. 

ny_state_data =
  brfss_smart2010_tidy %>%
  janitor::clean_names() %>%
  filter(.data = ., state_abbr == "NY", year == "2006" | year == "2010") %>%
  arrange(year)

# This code creates a two-panel plot showing the distribution of data values for the responses for NY state in 2006 and 2010.

ggplot(ny_state_data, aes(group = state_county, x = response, y = data_value, color = state_county)) + 
  geom_line() +
  facet_grid(~year) +
  theme_minimal() +
  theme(axis.title = element_text(size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Distribution of health responses in New York counties, 2006 and 2010", 
       x = "Health Response",
       y = "Proportion of health response") +
  scale_color_hue(name = "County in NY") +
    theme(legend.position = "bottom") 
```

## Problem 3

```{r load and clean dataset}
accel_data = 
  read.csv("./data/accel_data.csv") %>%
  rename(.data = ., num_of_day = day_id) %>%
  mutate(.data = ., 
         weekday_weekend = ifelse(day == "Monday" | day == "Tuesday" | day == "Wednesday" | day == "Thursday" | day == "Friday", "weekday", "weekend")) %>%
  select(.data = ., week, num_of_day, day, weekday_weekend, everything())
```

This dataset consists of five weeks of accelerometer data collected on a 63 year old man with BMI 25. There are `r ncol(accel_data)` variables and `r nrow(accel_data)` observations in this dataset. Of the 1444 variables in this dataset, 1440 variables represent the activity counts for each minute of a 24-hour day that starts as midnight. 

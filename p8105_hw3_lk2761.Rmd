---
title: "p8105_hw3_lk2761"
author: "Lorraine Kwok"
date: "October 8, 2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

## Problem 1 

We are using Instacart data. 

```{r load in Instacart dataset}
library(p8105.datasets) 
data("instacart")
```

```{r count number of aisles}
# This code produces a new dataframe that shows the number of distinct aisles and the number of items ordered from each. 

num_aisles_df = 
  instacart %>%
  count(aisle) %>%
  rename(.data = ., num_items_ordered = n) %>%
  arrange(desc(num_items_ordered))
```

```{r create plot for # of items ordered in each aisle}
num_aisles_df %>%
  filter(.data = ., num_items_ordered > 10000)
```

```{r create table for most popular items in three specific aisles}
# Create a table that shows the three most popular items in each of the aisles: baking ingredients, dog food care and packaged vegetables fruits.

num_pop_items_df =
  instacart %>%
  group_by(aisle) %>%
  select(.data = ., aisle, product_name) %>%
  filter(.data = ., aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>%
  count(product_name) %>%
  rename(.data = ., num_products = n) %>%
  arrange(desc(num_products)) %>%
  top_n(3) %>%
  pivot_wider(
    names_from = "aisle",
    values_from = "num_products"
  ) 

knitr::kable(num_pop_items_df)
```

```{r}
mean_hr_day_df = 
  instacart %>%
  select(.data = ., product_name, order_dow, order_hour_of_day) %>%
  mutate(.data = ., 
         order_dow = recode(order_dow, 
                            `0` = "Sunday",
                            `1` = "Monday",
                            `2` = "Tuesday", 
                            `3` = "Wednesday",
                            `4` = "Thursday", 
                            `5` = "Friday", 
                            `6` = "Saturday")) %>%
  filter(.data = ., product_name == "Pink Lady Apple" | product_name == "Coffee Ice Cream") %>%
  arrange(product_name, order_dow) %>%
  group_by(product_name, order_dow) %>%
  summarize(
    mean_hr_day = round(mean(order_hour_of_day), 2)
  ) %>%
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hr_day"
  ) %>%
  select(.data = ., Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)

knitr::kable(mean_hr_day_df)
```

## Problem 2

This problem uses the BRFSS dataset. 

```{r load in BRFSS dataset}
library(p8105.datasets)
data("brfss_smart2010")

# Clean the data
brfss_smart2010 %>%
  janitor::clean_names() %>%
  select(.data = ., topic, response) %>%
  filter(.data = ., topic == "Overall Health") %>%
  mutate(.data = ., response_fac = factor(response, c("Poor", "Fair", "Good", "Very good", "Excellent")))
```

```{r create dataframe for states in 2002 and 2010}
num_states_2002 = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  mutate(.data = . , location_name = state.name[match(locationabbr, state.abb)],) %>%
  filter(.data = ., year == "2002", topic == "Overall Health") %>%
  count(location_name) %>%
  rename(.data = ., num_locations = n) %>%
  filter(.data = ., num_locations >= 7) 

num_states_2002

num_states_2010 = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  mutate(.data = . , location_name = state.name[match(locationabbr, state.abb)],) %>%
  filter(.data = ., year == "2010", topic == "Overall Health") %>%
  count(location_name) %>%
  rename(.data = ., num_locations = n) %>%
  filter(.data = ., num_locations >= 7) 

num_states_2010
```

In 2002, the following states `r pull(num_states_2002, location_name)` were observed in 7 or more locations. In 2010, the following states `r pull(num_states_2010, location_name)` were observed in 7 or more locations.

```{r create new dataset with only excellent responses for Overall Health}

excellent_df = 
  brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(.data = ., topic == "Overall Health", response == "Excellent") %>%
  group_by(locationabbr) %>%
  mutate(.data = . , 
         state_name = state.name[match(locationabbr, state.abb)],
         avg_data_value = mean(data_value, na.rm = TRUE)) %>%
  select(.data = . , year, state_name, avg_data_value)

# This code creates a "spaghetti" plot showing the average data values across years for each state. 

ggplot(excellent_df, aes(group = state_name, x = year, y = avg_data_value, color = state_name)) + 
  geom_line()
```

